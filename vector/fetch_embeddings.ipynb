{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVJnO3SzTgt"
      },
      "source": [
        "\n",
        "Notebook to explore data similarity in DGraph cluster\n",
        "\n",
        "\n",
        "**pre-requesite**\n",
        "- Dgraph\n",
        "  - Get a [Dgraph Cloud account](https://cloud.dgraph.io/)\n",
        "  - Have your account user name and password available\n",
        "  - Have a Dgraph cluster running in your Dgraph Cloud account\n",
        "  - Obtain the GraphQL Endpoint of the Dgraph cluster from the [cloud dashboard](https://cloud.dgraph.io/_/dashboard)\n",
        "  - Obtain an Admin API key for the Dgraph Cluster from the [settings](https://cloud.dgraph.io/_/settings?tab=api-keys) tab.\n",
        "\n",
        "\n",
        "\n",
        "  The first step is to import the packages needed.\n",
        "\n",
        "-  ``pydgraph``, the official [python client library for Dgraph Query Language](https://dgraph.io/docs/dql/clients/python/)\n",
        "-  ``GraphqlClient``, a GraphQL client to invoke the GraphQL API generated from your schema and the GraphQL admin API of Dgraph.\n",
        "\n",
        "**Make sure to update the endpoints with the correct values for your Dgraph cluster!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qEDD3UC7uqF"
      },
      "outputs": [],
      "source": [
        "!pip install pydgraph python-graphql-client ipycytoscape\n",
        "import sys\n",
        "import pydgraph\n",
        "import json\n",
        "import base64\n",
        "import getpass\n",
        "import pandas as pd \n",
        "from python_graphql_client import GraphqlClient\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# copy your Dgraph cloud endpoints\n",
        "# The GraphQL endpoint is found at https://cloud.dgraph.io/_/dashboard\n",
        "# dgraph_graphql_endpoint = \"https://xyz.us-east-1.aws.cloud.dgraph.io/graphql\"\n",
        "dgraph_graphql_endpoint = \"http://localhost:8080/graphql\"\n",
        "\n",
        "\n",
        "# The gRPC endpoint is found at https://cloud.dgraph.io/_/settings\n",
        "# dgraph_grpc = \"xyz.grpc.us-east-1.aws.cloud.dgraph.io:443\"\n",
        "dgraph_grpc = \"localhost:9080\"\n",
        "\n",
        "# graph admin endpoint is /admin\n",
        "dgraph_graphql_admin = dgraph_graphql_endpoint.replace(\"/graphql\", \"/admin\")\n",
        "# graph health endpoint is /health\n",
        "dgraph_graphql_health = dgraph_graphql_endpoint.replace(\"/graphql\", \"/health\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qnQFABQNBXO"
      },
      "source": [
        "Enter your credentials and test the clients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7EvVHCqXzfV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cloud credentials\n",
        "# we need the cloud login credential to upload the Lambda code.\n",
        "# we need the an Admin API key generated at https://cloud.dgraph.io/_/settings?tab=api-keys for DQL alter and query\n",
        "\n",
        "\n",
        "API_KEY = getpass.getpass(\"DGRAPH API KEY?\")\n",
        "\n",
        "# DQL Client\n",
        "if dgraph_grpc.find(\"cloud\") > 0:\n",
        "   client_stub = pydgraph.DgraphClientStub.from_cloud(dgraph_grpc,API_KEY )\n",
        "else:\n",
        "   client_stub = pydgraph.DgraphClientStub(addr=dgraph_grpc) \n",
        "\n",
        "client = pydgraph.DgraphClient(client_stub)\n",
        "\n",
        "# GraphQL client and admin client\n",
        "gql_client = GraphqlClient(endpoint=dgraph_graphql_endpoint)\n",
        "headers = { \"Dg-Auth\": API_KEY }\n",
        "gql_admin_client = GraphqlClient(endpoint=dgraph_graphql_admin, headers=headers)\n",
        "gql_health_client = GraphqlClient(endpoint=dgraph_graphql_health)\n",
        "\n",
        "\n",
        "#\n",
        "#  Testing the connection to the Dgraph cluster\n",
        "#\n",
        "data = gql_health_client.execute(query=\"\")\n",
        "if 'errors' in data:\n",
        "   raise Exception(data['errors'][0]['message'])\n",
        "\n",
        "print(\"Check cluster health:\", json.dumps(data, indent=2))\n",
        "\n",
        "#\n",
        "#  Testing the DQL connection\n",
        "#\n",
        "txn = client.txn(read_only=True)\n",
        "query = \"schema{}\"\n",
        "res = txn.query(query)\n",
        "dqlschema = json.loads(res.json)\n",
        "txn.discard()\n",
        "print(\"get DQL schema - succeeded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeaFJyVJ8LlE"
      },
      "outputs": [],
      "source": [
        "# function to get embeddings from existing Dgraph cluster\n",
        "# update the query to match your schema, entity and embedding predicate\n",
        "\n",
        "\n",
        "def fetchEmbeddings(entity, emdedding_predicate, name_predicate):\n",
        "  # for example fetchEmbeddings(\"Product\",\"Product.embedding\",\"Product.title\")\n",
        "  # returns a dataframe with uid, name, and embedding\n",
        "  txn = client.txn(read_only=True)\n",
        "  after = \"\"\n",
        "  data = pd.DataFrame(columns=['uid', 'name', 'embedding'])\n",
        "  while True:\n",
        "    print(\"fetching products after\", after)\n",
        "    query = \"\"\"\n",
        "    query queryItems() {{\n",
        "        items(func:type({1}) {0},first:500)  @filter(has({2})) {{\n",
        "          uid\n",
        "          name: {3}\n",
        "          embedding:{2}\n",
        "        }}\n",
        "    }}\n",
        "    \"\"\".format(after,entity,emdedding_predicate,name_predicate)\n",
        "\n",
        "    variables = {}\n",
        "\n",
        "    res = txn.query(query, variables=variables)\n",
        "    jdata = json.loads(res.json)\n",
        "    print(len(jdata['items']))\n",
        "    if jdata['items'] == None or len(jdata['items']) == 0:\n",
        "      break\n",
        "    data = pd.concat([ data, pd.json_normalize(jdata['items']) ],ignore_index=True)\n",
        "    after = \"\"\",after: {}\"\"\".format(jdata['items'][-1]['uid'])\n",
        "    print(after)\n",
        "  return data\n",
        "\n",
        "\n",
        "def dataframe_to_rdf(data, filehandle = sys.stdout):\n",
        "    for _, row in data.iterrows():\n",
        "        rdf= \"\"\n",
        "        rdf += \"<_:{}> <Product.embedding> \\\"{}\\\" .\\n\".format(row['uid'],row['embedding'])\n",
        "        rdf += \"<_:{}> <Product.name> \\\"{}\\\" .\\n\".format(row['uid'],row['name'])\n",
        "        rdf += \"<_:{}> <dgraph.type> \\\"Product\\\" .\\n\".format(row['uid'])\n",
        "        filehandle.write(rdf)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gzip\n",
        "data = fetchEmbeddings(\"Product\",\"Product.embedding\",\"Product.name\")\n",
        "data.to_csv(\"products_with_embedding.csv.gz\",index=False,compression='gzip',header=True)\n",
        "# gzip file must use wt for write text\n",
        "with gzip.open(\"./products.rdf.gz\",\"wt\") as f:\n",
        "    dataframe_to_rdf(data, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
